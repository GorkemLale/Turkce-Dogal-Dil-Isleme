#!/usr/bin/env python3
"""
TEKNOFEST Model Yedekleme ve Fine-tuning Script
Gece Ã§alÄ±ÅŸacak, sabah hazÄ±r olacak
"""

import os
import json
import subprocess
import time
from datetime import datetime

def log_message(message):
    """Log mesajÄ± yazdÄ±r"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{timestamp}] {message}")
    with open("finetune_log.txt", "a", encoding="utf-8") as f:
        f.write(f"[{timestamp}] {message}\n")

def backup_current_model():
    """Mevcut modeli yedekle"""
    log_message("ğŸ”„ Model yedekleme baÅŸlatÄ±lÄ±yor...")
    
    try:
        # Ollama modelini listelele
        result = subprocess.run(["ollama", "list"], capture_output=True, text=True)
        log_message(f"Mevcut modeller:\n{result.stdout}")
        
        # Modeli yedekle
        log_message("ğŸ“¦ Model yedekleniyor...")
        backup_result = subprocess.run(
            ["ollama", "show", "mistral:7b-instruct"], 
            capture_output=True, text=True
        )
        
        if backup_result.returncode == 0:
            log_message("âœ… Model yedekleme baÅŸarÄ±lÄ±!")
            return True
        else:
            log_message(f"âŒ Model yedekleme hatasÄ±: {backup_result.stderr}")
            return False
            
    except Exception as e:
        log_message(f"âŒ Yedekleme hatasÄ±: {str(e)}")
        return False

def prepare_training_data():
    """Training verilerini hazÄ±rla"""
    log_message("ğŸ“ Training verileri hazÄ±rlanÄ±yor...")
    
    # Training data formatÄ±nÄ± Unsloth iÃ§in dÃ¶nÃ¼ÅŸtÃ¼r
    with open('training_data.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # Alpaca formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼r
    alpaca_data = []
    for item in data:
        alpaca_item = {
            "instruction": item["instruction"],
            "input": "",
            "output": item["output"]
        }
        alpaca_data.append(alpaca_item)
    
    with open('alpaca_training_data.json', 'w', encoding='utf-8') as f:
        json.dump(alpaca_data, f, ensure_ascii=False, indent=2)
    
    log_message(f"âœ… {len(alpaca_data)} veri Alpaca formatÄ±nda hazÄ±rlandÄ±!")
    return True

def install_requirements():
    """Gerekli kÃ¼tÃ¼phaneleri kur"""
    log_message("ğŸ“¦ Gerekli kÃ¼tÃ¼phaneler kuruluyor...")
    
    requirements = [
        "unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git",
        "torch>=2.1.0",
        "transformers>=4.36.0",
        "datasets",
        "accelerate",
        "bitsandbytes"
    ]
    
    for req in requirements:
        try:
            log_message(f"Kuruluyor: {req}")
            subprocess.run(["pip", "install", req], check=True)
        except subprocess.CalledProcessError as e:
            log_message(f"âŒ Kurulum hatasÄ±: {req} - {str(e)}")
            return False
    
    log_message("âœ… TÃ¼m kÃ¼tÃ¼phaneler kuruldu!")
    return True

def create_finetune_script():
    """Fine-tune script oluÅŸtur"""
    log_message("ğŸ› ï¸ Fine-tune script oluÅŸturuluyor...")
    
    script_content = '''
import torch
from unsloth import FastLanguageModel
from datasets import Dataset
import json

# Model yÃ¼kleme
model, tokenizer = FastLanguageModel.from_pretrained(
    model_name="unsloth/mistral-7b-instruct-v0.2-bnb-4bit",
    max_seq_length=2048,
    dtype=None,
    load_in_4bit=True,
)

# LoRA adaptÃ¶rÃ¼ ekle
model = FastLanguageModel.get_peft_model(
    model,
    r=16,
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj",
                   "gate_proj", "up_proj", "down_proj"],
    lora_alpha=16,
    lora_dropout=0,
    bias="none",
    use_gradient_checkpointing="unsloth",
    random_state=3407,
)

# Training verilerini yÃ¼kle
with open('alpaca_training_data.json', 'r', encoding='utf-8') as f:
    train_data = json.load(f)

dataset = Dataset.from_list(train_data)

def formatting_prompts_func(examples):
    instructions = examples["instruction"]
    inputs = examples["input"]
    outputs = examples["output"]
    texts = []
    for instruction, input, output in zip(instructions, inputs, outputs):
        text = f"""Sen bir TÃ¼rk Telekom Ã§aÄŸrÄ± merkezi temsilcisisin.

MÃ¼ÅŸteri: {instruction}
Temsilci: {output}"""
        texts.append(text)
    return {"text": texts}

dataset = dataset.map(formatting_prompts_func, batched=True)

from trl import SFTTrainer
from transformers import TrainingArguments

trainer = SFTTrainer(
    model=model,
    tokenizer=tokenizer,
    train_dataset=dataset,
    dataset_text_field="text",
    max_seq_length=2048,
    dataset_num_proc=2,
    args=TrainingArguments(
        per_device_train_batch_size=2,
        gradient_accumulation_steps=4,
        warmup_steps=5,
        max_steps=50,
        learning_rate=2e-4,
        fp16=not torch.cuda.is_bf16_supported(),
        bf16=torch.cuda.is_bf16_supported(),
        logging_steps=1,
        optim="adamw_8bit",
        weight_decay=0.01,
        lr_scheduler_type="linear",
        seed=3407,
        output_dir="outputs",
        save_steps=25,
    ),
)

# Training baÅŸlat
print("ğŸš€ Fine-tuning baÅŸlatÄ±lÄ±yor...")
trainer.train()

# Model kaydet
model.save_pretrained("teknofest_finetuned_model")
tokenizer.save_pretrained("teknofest_finetuned_model")

print("âœ… Fine-tuning tamamlandÄ±!")
print("ğŸ“ Model kaydedildi: teknofest_finetuned_model/")
'''
    
    with open('finetune_script.py', 'w', encoding='utf-8') as f:
        f.write(script_content)
    
    log_message("âœ… Fine-tune script oluÅŸturuldu!")
    return True

def start_finetune():
    """Fine-tuning iÅŸlemini baÅŸlat"""
    log_message("ğŸš€ Fine-tuning baÅŸlatÄ±lÄ±yor...")
    log_message("â° Bu iÅŸlem 2-4 saat sÃ¼rebilir...")
    
    try:
        # Screen session baÅŸlat
        subprocess.run([
            "screen", "-dmS", "teknofest_finetune", 
            "python", "finetune_script.py"
        ])
        log_message("âœ… Fine-tuning screen session'da baÅŸlatÄ±ldÄ±!")
        log_message("ğŸ“‹ Kontrol iÃ§in: screen -r teknofest_finetune")
        return True
        
    except Exception as e:
        log_message(f"âŒ Fine-tuning baÅŸlatma hatasÄ±: {str(e)}")
        return False

def main():
    """Ana fonksiyon"""
    log_message("ğŸ¯ TEKNOFEST Fine-tuning SÃ¼reci BaÅŸlatÄ±lÄ±yor!")
    log_message("=" * 50)
    
    # 1. Model yedekleme
    if not backup_current_model():
        log_message("âŒ Model yedekleme baÅŸarÄ±sÄ±z, devam ediliyor...")
    
    # 2. Training verilerini hazÄ±rla
    if not prepare_training_data():
        log_message("âŒ Training verileri hazÄ±rlanamadÄ±!")
        return
    
    # 3. KÃ¼tÃ¼phaneleri kur
    if not install_requirements():
        log_message("âŒ KÃ¼tÃ¼phane kurulumu baÅŸarÄ±sÄ±z!")
        return
    
    # 4. Fine-tune script oluÅŸtur
    if not create_finetune_script():
        log_message("âŒ Script oluÅŸturulamadÄ±!")
        return
    
    # 5. Fine-tuning baÅŸlat
    if not start_finetune():
        log_message("âŒ Fine-tuning baÅŸlatÄ±lamadÄ±!")
        return
    
    log_message("ğŸ‰ TÃ¼m iÅŸlemler baÅŸarÄ±yla baÅŸlatÄ±ldÄ±!")
    log_message("â° Sabah kontrol edin: screen -r teknofest_finetune")
    log_message("ğŸ“„ Log takibi: tail -f finetune_log.txt")

if __name__ == "__main__":
    main()